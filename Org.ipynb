{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_images(images, cmap=None):\n",
    "    cols = 2\n",
    "    rows = (len(images)+1)//cols\n",
    "    \n",
    "    plt.figure(figsize=(15, 12))\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        # use gray scale color map if there is only one channel\n",
    "        cmap = 'gray' if len(image.shape)==2 else cmap\n",
    "        plt.imshow(image, cmap=cmap)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.tight_layout(pad=0, h_pad=0, w_pad=0)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def detect_edges(image, low_threshold , high_threshold):\n",
    "    return cv2.Canny(image, low_threshold, high_threshold)\n",
    "\n",
    "def suavizar_gaussian(image,d=5, e= 5):\n",
    "    return cv2.GaussianBlur(image,(d, e),0)\n",
    "    #return cv2.GaussianBlur(image, (n1, n2), 0)\n",
    "\n",
    "def hough_lines(image):\n",
    "    \"\"\"\n",
    "    `image` should be the output of a Canny transform.\n",
    "    \n",
    "    Returns hough lines (not the image with lines)\n",
    "    \"\"\" \n",
    "    return cv2.HoughLinesP(image, rho=0.1, theta=np.pi/10, threshold=15, minLineLength=9, maxLineGap=4)\n",
    "\n",
    "def draw_lines(image, lines, color=[255, 0, 0], thickness=2, make_copy=True):\n",
    "    # the lines returned by cv2.HoughLinesP has the shape (-1, 1, 4)\n",
    "    if make_copy:\n",
    "        image = np.copy(image) # don't want to modify the original\n",
    "    cleaned = []\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            if abs(y2-y1) <=1 and abs(x2-x1) >=25 and abs(x2-x1) <= 55:\n",
    "                cleaned.append((x1,y1,x2,y2))\n",
    "                cv2.line(image, (x1, y1), (x2, y2), color, thickness)\n",
    "    print(\" No lines detected: \", len(cleaned))\n",
    "    return image\n",
    "\n",
    "def select_rgb_white_yellow(image): \n",
    "    # white color mask\n",
    "    lower = np.uint8([120, 120, 120])\n",
    "    upper = np.uint8([255, 255, 255])\n",
    "    white_mask = cv2.inRange(image, lower, upper)\n",
    "    # yellow color mask\n",
    "    lower = np.uint8([190, 190,   0])\n",
    "    upper = np.uint8([255, 255, 255])\n",
    "    yellow_mask = cv2.inRange(image, lower, upper)\n",
    "    # combine the mask\n",
    "    mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
    "    masked = cv2.bitwise_and(image, image, mask = mask)\n",
    "    return masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Esqueleto\n",
    "\n",
    "\n",
    "\n",
    "height,width = mask.shape\n",
    "skel = np.zeros([height,width],dtype=np.uint8)      #[height,width,3]\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3))\n",
    "temp_nonzero = np.count_nonzero(mask)\n",
    "\n",
    "while(np.count_nonzero(mask) != 0 ):\n",
    "    eroded = cv2.erode(mask,kernel)\n",
    "    #cv2.imshow(\"eroded\",eroded)   \n",
    "    temp = cv2.dilate(eroded,kernel)\n",
    "    #cv2.imshow(\"dilate\",temp)\n",
    "    temp = cv2.subtract(mask,temp)\n",
    "    skel = cv2.bitwise_or(skel,temp)\n",
    "    mask = eroded.copy()\n",
    "\n",
    "#cv2.imshow(\"skel\",skel)\n",
    "\n",
    "plt.imshow(skel, cmap='gray')\n",
    "plt.subplots_adjust(left=0.0, right=4.0, bottom=0.0, top=3.0) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_rgb_white_yellow(image): \n",
    "    # white color mask\n",
    "    lower = np.uint8([120, 120, 120])\n",
    "    upper = np.uint8([255, 255, 255])\n",
    "    white_mask = cv2.inRange(image, lower, upper)\n",
    "    # yellow color mask\n",
    "    lower = np.uint8([190, 190,   0])\n",
    "    upper = np.uint8([255, 255, 255])\n",
    "    yellow_mask = cv2.inRange(image, lower, upper)\n",
    "    # combine the mask\n",
    "    mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
    "    masked = cv2.bitwise_and(image, image, mask = mask)\n",
    "    return masked\n",
    "\n",
    "result = select_rgb_white_yellow(crop_img)\n",
    "mask = result\n",
    "plt.imshow(result)\n",
    "plt.subplots_adjust(left=0.0, right=4.0, bottom=0.0, top=3.0) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def suavizar_gaussian(image,d=5, e= 5):\n",
    "    return cv2.GaussianBlur(image,(d, e),0) \n",
    "\n",
    "blur_gray = suavizar_gaussian(skel)\n",
    "\n",
    "\n",
    "plt.imshow(blur_gray, cmap='gray')\n",
    "plt.subplots_adjust(left=0.0, right=4.0, bottom=0.0, top=3.0) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edges = detect_edges(blur_gray, 50 , 150)\n",
    "\n",
    "plt.imshow(edges, cmap='gray')\n",
    "plt.subplots_adjust(left=0.0, right=4.0, bottom=0.0, top=3.0) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rho = 1  # distance resolution in pixels of the Hough grid\n",
    "theta = np.pi / 180  # angular resolution in radians of the Hough grid\n",
    "threshold = 15  # minimum number of votes (intersections in Hough grid cell)\n",
    "min_line_length = 10  # minimum number of pixels making up a line\n",
    "max_line_gap = 10  # maximum gap in pixels between connectable line segments\n",
    "line_image = np.copy(crop_img) * 0  # creating a blank to draw lines on\n",
    "#min_line_length = 10 \n",
    "#max_line_gap = 10 \n",
    "\n",
    "# Run Hough on edge detected image\n",
    "# Output \"lines\" is an array containing endpoints of detected line segments\n",
    "lines = cv2.HoughLinesP(edges, rho, theta, threshold, np.array([]),\n",
    "                    min_line_length, max_line_gap)\n",
    "\n",
    "points = []\n",
    "for line in lines:\n",
    "    for x1,y1,x2,y2 in line:\n",
    "        points.append(((x1 + 0.0, y1 + 0.0), (x2 + 0.0, y2 + 0.0)))\n",
    "        cv2.line(line_image,(x1,y1),(x2,y2),(255,0,0),5)\n",
    "        \n",
    "        \n",
    "lines_edges = cv2.addWeighted(crop_img, 0.8, line_image, 1, 0)\n",
    "plt.imshow(lines_edges , cmap='gray')\n",
    "plt.subplots_adjust(left=0.0, right=4.0, bottom=0.0, top=3.0) \n",
    "# rho=0.1, theta=np.pi/10, threshold=15, minLineLength=9, maxLineGap=4\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Detectando Linhas Paralelas\n",
    "#def identify_blocks(image, lines, make_copy=True):\n",
    "#    if make_copy:\n",
    "#        new_image = np.copy(image)\n",
    "    #Step 1: Create a clean list of lines\n",
    "#    cleaned = []\n",
    "#    for line in lines:\n",
    "#        for x1,y1,x2,y2 in line:\n",
    "#            if abs(y2-y1) <=1 and abs(x2-x1) >=25 and abs(x2-x1) <= 55:\n",
    "#                cleaned.append((x1,y1,x2,y2))\n",
    "    \n",
    "    #Step 2: Sort cleaned by x1 position\n",
    "#    import operator\n",
    "#    list1 = sorted(cleaned, key=operator.itemgetter(0, 1))\n",
    "    \n",
    "    #Step 3: Find clusters of x1 close together - clust_dist apart\n",
    "#    clusters = {}\n",
    "#    dIndex = 0\n",
    "#    clus_dist = 10\n",
    "\n",
    "#    for i in range(len(list1) - 1):\n",
    "#        distance = abs(list1[i+1][0] - list1[i][0])\n",
    "    #         print(distance)\n",
    "#        if distance <= clus_dist:\n",
    "#            if not dIndex in clusters.keys(): clusters[dIndex] = []\n",
    "#            clusters[dIndex].append(list1[i])\n",
    "#            clusters[dIndex].append(list1[i + 1])\n",
    "\n",
    "#        else:\n",
    "#            dIndex += 1\n",
    "    \n",
    "    #Step 4: Identify coordinates of rectangle around this cluster\n",
    "#    rects = {}\n",
    "#    i = 0\n",
    "#    for key in clusters:\n",
    "#        all_list = clusters[key]\n",
    "#        cleaned = list(set(all_list))\n",
    "#        if len(cleaned) > 5:\n",
    "#            cleaned = sorted(cleaned, key=lambda tup: tup[1])\n",
    "#            avg_y1 = cleaned[0][1]\n",
    "#            avg_y2 = cleaned[-1][1]\n",
    "    #         print(avg_y1, avg_y2)\n",
    "#            avg_x1 = 0\n",
    "#            avg_x2 = 0\n",
    "#            for tup in cleaned:\n",
    "#                avg_x1 += tup[0]\n",
    "#               avg_x2 += tup[2]\n",
    "#            avg_x1 = avg_x1/len(cleaned)\n",
    "#            avg_x2 = avg_x2/len(cleaned)\n",
    "#            rects[i] = (avg_x1, avg_y1, avg_x2, avg_y2)\n",
    "#            i += 1\n",
    "    \n",
    "#    print(\"Num Parking Lanes: \", len(rects))\n",
    "    #Step 5: Draw the rectangles on the image\n",
    "#    buff = 7\n",
    "#    for key in rects:\n",
    "#        tup_topLeft = (int(rects[key][0] - buff), int(rects[key][1]))\n",
    "#        tup_botRight = (int(rects[key][2] + buff), int(rects[key][3]))\n",
    "#         print(tup_topLeft, tup_botRight)\n",
    "#        cv2.rectangle(new_image, tup_topLeft,tup_botRight,(0,255,0),3)\n",
    "#    return new_image, rects\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# images showing the region of interest only\n",
    "#rect_images = []\n",
    "#rect_coords = []\n",
    "#for image, lines in zip(test_images, list_of_lines):\n",
    "#new_image, rects = identify_blocks(line_image, lines)\n",
    "#rect_images.append(new_image)\n",
    "#rect_coords.append(rects)\n",
    "    \n",
    "#show_images(rect_images)\n",
    "\n",
    "\n",
    "#plt.imshow(new_image , cmap='gray')\n",
    "#plt.subplots_adjust(left=0.0, right=4.0, bottom=0.0, top=3.0) \n",
    "#plt.show() \n",
    "\n",
    "\n",
    "#linhas_paralelas = findparallel(lines)\n",
    "#lines[0]\n",
    "\n",
    "#import itertools\n",
    "\n",
    "#paralelas = ([])\n",
    "#for pair in itertools.combinations(lines, r=3):\n",
    "#    paralelas.append(([pair[0], pair[1]]))\n",
    "    \n",
    "#paralelas[0]\n",
    "#len(paralelas)    \n",
    "\n",
    "#imgTeste = np.copy(crop_img)\n",
    "\n",
    "#cv2.rectangle(imgTeste,(384,300),(510,128),(0,255,0),3)\n",
    "\n",
    "#plt.imshow(imgTeste , cmap='gray')\n",
    "#plt.subplots_adjust(left=0.0, right=4.0, bottom=0.0, top=3.0) \n",
    "#plt.show() \n",
    "\n",
    "#https://stackoverflow.com/questions/15780210/python-opencv-detect-parallel-lines\n",
    "#def findparallel(lines):\n",
    "#    lines1 = []\n",
    "#    for i in range(len(lines)-1):\n",
    "#        for j in range(len(lines)-1):\n",
    "#            if (i == j):continue\n",
    "#            if (abs(lines[i][1] - lines[j][1]) == 0):          \n",
    "#                 #You've found a parallel line!\n",
    "#                     lines1.append((i,j))\n",
    "\n",
    "\n",
    "#    return lines1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
